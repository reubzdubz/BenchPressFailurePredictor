# -*- coding: utf-8 -*-
"""Another copy of Mediapipe.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ij_kVmZkJdgr580ymuqbsslyTyeM3R7p
"""

!pip install numpy==2.0.0
!pip install mediapipe

!pip install opencv-python
!pip install pandas
!pip install pillow

from google.colab import drive
drive.mount('/content/drive')



"""# Benching"""

from google.colab import files
import math

uploaded = files.upload()   # choose your .mp4/.mov
# Get the filename from the uploaded dictionary and remove the extension
in_path = list(uploaded.keys())[0]
new_filename = in_path.replace(".mp4", "")
out_path = new_filename + '_with_counts.mp4'
print("Processing:", in_path)

import cv2, os, time, io, numpy as np
from collections import deque
from base64 import b64decode
from PIL import Image
from google.colab import output
from IPython.display import Javascript, display, clear_output
import pandas as pd
import matplotlib.pyplot as plt

import mediapipe as mp
mp_pose   = mp.solutions.pose
mp_draw   = mp.solutions.drawing_utils
mp_styles = mp.solutions.drawing_styles

pose = mp_pose.Pose(
    static_image_mode=False,
    model_complexity=2,
    smooth_landmarks=True,       # ensure smoothing is on
    enable_segmentation=False,
    smooth_segmentation=False,
    min_detection_confidence=0.7,
    min_tracking_confidence=0.7
)


def angle_3pt(a, b, c):
    a, b, c = np.array(a), np.array(b), np.array(c)
    ba = a - b
    bc = c - b
    cosang = np.dot(ba, bc) / (np.linalg.norm(ba)*np.linalg.norm(bc) + 1e-9)
    cosang = np.clip(cosang, -1.0, 1.0)
    return np.degrees(np.arccos(cosang))

class BenchCounter:
    def __init__(self, elbow_low_thresh=70, elbow_high_thresh=165, bar_down_delta=0.06, smooth=5, refractory_frames=6):
        self.elbow_low_thresh  = elbow_low_thresh
        self.elbow_high_thresh = elbow_high_thresh
        self.bar_down_delta    = bar_down_delta
        self.stage = "top"
        self.count = 0
        self.elbow_angles = deque(maxlen=smooth)
        self.bar_y_vals   = deque(maxlen=smooth)
        self.personal_top_bar_y = None
        self.frames_since_top   = refractory_frames
        self.refractory_frames  = refractory_frames

    def update(self, left_elbow_angle, right_elbow_angle, bar_y, left_vis, right_vis, bar_valid):
        if left_vis and right_vis:
            elbow_angle = 0.5*(left_elbow_angle + right_elbow_angle)
        elif left_vis:
            elbow_angle = left_elbow_angle
        elif right_vis:
            elbow_angle = right_elbow_angle
        else:
            elbow_angle = 180.0
        self.elbow_angles.append(elbow_angle)

        if bar_valid:
            self.bar_y_vals.append(bar_y)
        elif len(self.bar_y_vals) == 0:
            self.bar_y_vals.append(0.0)

        sm_elbow = float(np.mean(self.elbow_angles))
        sm_bar_y = float(np.mean(self.bar_y_vals))

        if sm_elbow >= self.elbow_high_thresh and bar_valid:
            if self.personal_top_bar_y is None:
                self.personal_top_bar_y = sm_bar_y
            else:
                self.personal_top_bar_y = min(self.personal_top_bar_y, sm_bar_y)

        self.frames_since_top += 1

        if self.stage == "top":
            down_ok = False
            if (self.personal_top_bar_y is not None) and bar_valid:
                down_ok = (sm_bar_y - self.personal_top_bar_y) >= self.bar_down_delta
            else:
                down_ok = True
            if (sm_elbow <= self.elbow_low_thresh) and down_ok:
                self.stage = "bottom"
                self.frames_since_top = 0

        elif self.stage == "bottom":
            if (sm_elbow >= self.elbow_high_thresh) and (self.frames_since_top >= self.refractory_frames):
                self.stage = "top"
                self.count += 1
                self.frames_since_top = 0

        return sm_elbow, sm_bar_y, self.count, self.stage, (self.personal_top_bar_y or 0.0)

from dataclasses import dataclass

@dataclass
class ROIState:
    x0:int; y0:int; x1:int; y1:int
    cx:float; cy:float; scale:float
    lost:int = 0

def bbox_from_landmarks_xy_norm(xy_norm, W, H, margin=0.25):
    if len(xy_norm)==0: return None
    xs = xy_norm[:,0]; ys = xy_norm[:,1]
    x0 = max(0, int((xs.min()-margin)*W))
    x1 = min(W, int((xs.max()+margin)*W))
    y0 = max(0, int((ys.min()-margin)*H))
    y1 = min(H, int((ys.max()+margin)*H))
    cx = 0.5*(x0+x1); cy = 0.5*(y0+y1)
    scale = max(x1-x0, y1-y0)
    return ROIState(x0,y0,x1,y1,cx,cy,scale,0)

def gate_roi(prev: ROIState, curr: ROIState, max_jump_px=120, max_scale_ratio=1.8):
    if prev is None or curr is None: return True
    jump = ((curr.cx-prev.cx)**2+(curr.cy-prev.cy)**2)**0.5
    sr = max(curr.scale,1e-6)/max(prev.scale,1e-6)
    sr = sr if sr>=1 else 1/sr
    return (jump<=max_jump_px) and (sr<=max_scale_ratio)

def crop_by_roi(frame, roi: ROIState):
    if roi is None:
        return frame, (0,0,frame.shape[1],frame.shape[0])
    return frame[roi.y0:roi.y1, roi.x0:roi.x1], (roi.x0, roi.y0, roi.x1-roi.x0, roi.y1-roi.y0)

def reproject_landmarks_from_crop(lm_list, offx, offy, cw, ch, W, H):
    xs = np.array([p.x*(cw-1) for p in lm_list], float)
    ys = np.array([p.y*(ch-1) for p in lm_list], float)
    xs_full = xs+offx; ys_full = ys+offy
    xs_n = xs_full/(W-1); ys_n = ys_full/(H-1)
    return np.stack([xs_n, ys_n], axis=1)

# ----- Pass 1: metrics -----
cap = cv2.VideoCapture(in_path)
if not cap.isOpened():
    raise RuntimeError(f"Cannot open video: {in_path}")
roi = None       # no ROI yet
MAX_LOST = 8     # frames to tolerate before re-detecting full frame
MARGIN   = 0.25  # padding around person
bench = BenchCounter()
rows = []

while True:
    ret, frame = cap.read()
    if not ret: break
    H, W = frame.shape[:2]

    # --- choose ROI crop if locked ---
    crop_img, (offx, offy, cw, ch) = crop_by_roi(frame, roi)
    rgb = cv2.cvtColor(crop_img, cv2.COLOR_BGR2RGB)
    res = pose.process(rgb)

    # defaults
    l_ang = r_ang = 180.0; bar_y = 0.0
    l_vis = r_vis = False; bar_valid = False

    if res.pose_landmarks:
        lm  = res.pose_landmarks.landmark
        xy_full = reproject_landmarks_from_crop(lm, offx, offy, cw, ch, W, H)
        vis = np.array([p.visibility for p in lm], float)

        curr = bbox_from_landmarks_xy_norm(xy_full, W, H, margin=MARGIN)
        if gate_roi(roi, curr):
            roi = curr; roi.lost = 0
            # ---- your usual angle/bar computations here ----
            def P(i): return (xy_full[i,0], xy_full[i,1]), vis[i]
            (LSH,vLSH)=P(mp_pose.PoseLandmark.LEFT_SHOULDER.value)
            (LEL,vLEL)=P(mp_pose.PoseLandmark.LEFT_ELBOW.value)
            (LWR,vLWR)=P(mp_pose.PoseLandmark.LEFT_WRIST.value)
            (RSH,vRSH)=P(mp_pose.PoseLandmark.RIGHT_SHOULDER.value)
            (REL,vREL)=P(mp_pose.PoseLandmark.RIGHT_ELBOW.value)
            (RWR,vRWR)=P(mp_pose.PoseLandmark.RIGHT_WRIST.value)
            l_vis=(vLSH>0.5)&(vLEL>0.5)&(vLWR>0.5)
            r_vis=(vRSH>0.5)&(vREL>0.5)&(vRWR>0.5)
            if l_vis: l_ang=angle_3pt(LSH,LEL,LWR)
            if r_vis: r_ang=angle_3pt(RSH,REL,RWR)
            if vLWR>0.5 and vRWR>0.5:
                bar_y=0.5*(LWR[1]+RWR[1]); bar_valid=True
            elif vLWR>0.5: bar_y=LWR[1]; bar_valid=True
            elif vRWR>0.5: bar_y=RWR[1]; bar_valid=True
        else:
            if roi: roi.lost += 1
    else:
        if roi: roi.lost += 1

    if roi and roi.lost >= MAX_LOST:
        roi = None

    sm_elbow, sm_bar_y, cnt, stage, personal_top_y = bench.update(
        l_ang, r_ang, bar_y, l_vis, r_vis, bar_valid
    )

    rows.append({
        "sm_elbow_angle": sm_elbow,
        "sm_bar_y": sm_bar_y,
        "rep_count": cnt,
        "stage": stage,
        "personal_top_bar_y": personal_top_y
    })

cap.release(); pose.close()

df = pd.DataFrame(rows)
print(df.head())
print("Frames:", len(df))
if len(df):
    print("Elbow angle range:", f"{df['sm_elbow_angle'].min():.1f}–{df['sm_elbow_angle'].max():.1f}")
    valid_bar = df['sm_bar_y'].replace(0, np.nan)
    print("Bar y (norm) range:", f"{valid_bar.min():.3f}–{valid_bar.max():.3f}")
    print("Reps detected:", int(df['rep_count'].iloc[-1]))

# ----- Pass 2: writer (ROI-locked) -----
cap = cv2.VideoCapture(in_path)
w  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
h  = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fps= cap.get(cv2.CAP_PROP_FPS) or 30.0

out_path = new_filename + '_with_counts.mp4'
writer = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w,h))

def draw_hud(frame, sm_elbow, sm_bar_y, cnt, stage, personal_top_y):
    H, W = frame.shape[:2]
    x0,y0,w0,h0 = 10,10,360,125
    cv2.rectangle(frame, (x0,y0), (x0+w0,y0+h0), (0,0,0), -1)
    cv2.putText(frame, 'BENCH PRESS', (x0+10,y0+28), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255,255,255), 2)
    cv2.putText(frame, f'Elbow Angle: {int(sm_elbow)} deg', (x0+10,y0+58), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (255,255,255), 2)
    cv2.putText(frame, f'Bar y (norm): {sm_bar_y:.3f}', (x0+10,y0+83), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (255,255,255), 2)
    cv2.putText(frame, f'Reps: {cnt}   Stage: {stage}', (x0+10,y0+108), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,255), 2)
    if personal_top_y > 0:
        y_line = int(personal_top_y * H)
        cv2.line(frame, (W-140, y_line), (W-10, y_line), (0,255,255), 2)
        cv2.putText(frame, 'Top ref', (W-138, max(20, y_line-6)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,255), 1)
    return frame

bench2 = BenchCounter()

# ROI tracker state & params
roi = None         # will lock after first accepted detection
MAX_LOST = 8       # frames to allow before re-detecting full frame
MARGIN   = 0.25    # padding around landmarks for ROI

with mp_pose.Pose(static_image_mode=False, model_complexity=2,
                  enable_segmentation=False, min_detection_confidence=0.7,
                  min_tracking_confidence=0.7) as pose2:

    while True:
        ret, frame = cap.read()
        if not ret:
            break
        H, W = frame.shape[:2]

        # choose crop based on current ROI (or full frame if not locked)
        crop_img, (offx, offy, cw, ch) = crop_by_roi(frame, roi)

        # run pose on the crop
        rgb = cv2.cvtColor(crop_img, cv2.COLOR_BGR2RGB)
        res = pose2.process(rgb)

        # defaults
        l_ang = r_ang = 180.0
        bar_y = 0.0
        l_vis = r_vis = False
        bar_valid = False

        drew_landmarks = False

        if res.pose_landmarks:
            lm = res.pose_landmarks.landmark

            # draw landmarks on the crop (so visuals align with ROI)
            mp_draw.draw_landmarks(
                crop_img, res.pose_landmarks, mp_pose.POSE_CONNECTIONS,
                landmark_drawing_spec=mp_styles.get_default_pose_landmarks_style()
            )
            drew_landmarks = True

            # reproject crop-normalized -> full-frame normalized
            xy_full = reproject_landmarks_from_crop(lm, offx, offy, cw, ch, W, H)
            vis = np.array([p.visibility for p in lm], float)

            # propose current ROI from this detection
            curr = bbox_from_landmarks_xy_norm(xy_full, W, H, margin=MARGIN)

            # gate update: only accept if near previous center/scale
            if gate_roi(roi, curr, max_jump_px=120, max_scale_ratio=1.8):
                roi = curr
                roi.lost = 0

                # compute angles/bar using full-frame normalized coords
                def P(i): return (xy_full[i,0], xy_full[i,1]), vis[i]

                (LSH,vLSH)=P(mp_pose.PoseLandmark.LEFT_SHOULDER.value)
                (LEL,vLEL)=P(mp_pose.PoseLandmark.LEFT_ELBOW.value)
                (LWR,vLWR)=P(mp_pose.PoseLandmark.LEFT_WRIST.value)
                (RSH,vRSH)=P(mp_pose.PoseLandmark.RIGHT_SHOULDER.value)
                (REL,vREL)=P(mp_pose.PoseLandmark.RIGHT_ELBOW.value)
                (RWR,vRWR)=P(mp_pose.PoseLandmark.RIGHT_WRIST.value)

                l_vis=(vLSH>0.5) and (vLEL>0.5) and (vLWR>0.5)
                r_vis=(vRSH>0.5) and (vREL>0.5) and (vRWR>0.5)

                if l_vis: l_ang = angle_3pt(LSH, LEL, LWR)
                if r_vis: r_ang = angle_3pt(RSH, REL, RWR)

                if vLWR>0.5 and vRWR>0.5:
                    bar_y = 0.5*(LWR[1] + RWR[1]); bar_valid = True
                elif vLWR>0.5:
                    bar_y = LWR[1]; bar_valid = True
                elif vRWR>0.5:
                    bar_y = RWR[1]; bar_valid = True

            else:
                # reject (likely different person), keep prior roi
                if roi: roi.lost += 1
        else:
            # no landmarks in this crop
            if roi: roi.lost += 1

        # if tracking lost too long, reset to full-frame next frame
        if roi and roi.lost >= MAX_LOST:
            roi = None

        # if we drew on crop, paste back into full frame for output visualization
        if drew_landmarks:
            frame[offy:offy+ch, offx:offx+cw] = crop_img

        # (optional) draw ROI box for debugging
        # if roi:
        #     cv2.rectangle(frame, (roi.x0, roi.y0), (roi.x1, roi.y1), (0,255,255), 2)

        # update HUD + write
        sm_elbow, sm_bar_y, cnt, stage, personal_top_y = bench2.update(
            l_ang, r_ang, bar_y, l_vis, r_vis, bar_valid
        )
        frame = draw_hud(frame, sm_elbow, sm_bar_y, cnt, stage, personal_top_y)
        writer.write(frame)

cap.release(); writer.release()
print("Saved:", out_path)

save_dir = "/content/drive/MyDrive/3201 Data"  # change if you like
os.makedirs(save_dir, exist_ok=True)
# --- assumes df already exists with sm_elbow_angle, sm_bar_y, rep_count ---

# Find rep events (where the count increases)
rep_steps = df['rep_count'].diff().fillna(0)
rep_idx = df.index[rep_steps > 0]

# 1) Elbow angle over time (with rep markers)
fig1, ax = plt.subplots(figsize=(12, 4))
ax.plot(df.index, df['sm_elbow_angle'])
for i in rep_idx:
    ax.axvline(i, linestyle='--', alpha=0.5)
ax.set_xlabel('Frame')
ax.set_ylabel('Elbow Angle (deg)')
ax.set_title('Elbow Angle Over Time (rep markers)')
ax.grid(True)
fig1_path = os.path.join(save_dir, f"bench_sm_elbow_angle_{new_filename}.png")
fig1.savefig(fig1_path, dpi=200, bbox_inches='tight')
plt.show()

fig2, ax = plt.subplots(figsize=(12, 4))
ax.plot(df.index, df['sm_bar_y'])
for i in rep_idx:
    ax.axvline(i, linestyle='--', alpha=0.5)
ax.invert_yaxis()
ax.set_xlabel('Frame')
ax.set_ylabel('Bar Y (normalized)')
ax.set_title('Bar Height Proxy Over Time (rep markers)')
ax.grid(True)
fig2_path = os.path.join(save_dir, f"bench_sm_bar_y_{new_filename}.png")
fig2.savefig(fig2_path, dpi=200, bbox_inches='tight')
plt.show()

fig3, ax = plt.subplots(figsize=(12, 4))
ax.plot(df.index, df['rep_count'])
ax.set_xlabel('Frame')
ax.set_ylabel('Bench Count')
ax.set_title('Bench Count Over Time')
ax.grid(True)
fig3_path = os.path.join(save_dir, f"bench_rep_count_{new_filename}.png")
fig3.savefig(fig3_path, dpi=200, bbox_inches='tight')
plt.show()

# 3) Build a timestamped filename and save
csv_path = os.path.join(save_dir, f"bench_frame_metrics_{new_filename}.csv")

# Safety check: df should exist (from Pass 1)
if 'df' not in globals():
    raise RuntimeError("DataFrame 'df' not found. Run Pass 1 to create it first.")

df.to_csv(csv_path, index=False)
print(f"Saved CSV to: {csv_path}")

from google.colab import files
files.download(out_path)

